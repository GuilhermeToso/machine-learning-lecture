{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e86d1bf9",
   "metadata": {},
   "source": [
    "# Aprendizado por Reforço\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db399d2d",
   "metadata": {},
   "source": [
    "Neste notebook será introduziado a aplicação do aprendizado por reforço utilizando um algoritmo de Deep Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c96920",
   "metadata": {},
   "source": [
    "## Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6339c07a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-02T15:54:50.643486Z",
     "start_time": "2022-07-02T15:54:50.631465Z"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaaf0903",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-02T16:00:32.849992Z",
     "start_time": "2022-07-02T16:00:25.664573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([1,2,3])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e39852",
   "metadata": {},
   "source": [
    "## Explorando o Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35662e8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T18:43:50.762537Z",
     "start_time": "2022-06-30T18:43:50.739468Z"
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"HalfCheetah-v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c7a6b0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T20:50:33.327849Z",
     "start_time": "2022-06-30T20:50:33.308871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of State Space -> 17\n",
      "Size of Action Space -> 6\n",
      "Max Value of Action -> 1.0\n",
      "Min Value of Action -> -1.0\n"
     ]
    }
   ],
   "source": [
    "num_states = env.observation_space.shape[0]\n",
    "print(f\"Size of State Space -> {num_states}\")\n",
    "num_actions = env.action_space.shape[0]\n",
    "print(f\"Size of Action Space -> {num_actions}\")\n",
    "\n",
    "upper_bound = env.action_space.high[0]\n",
    "lower_bound = env.action_space.low[0]\n",
    "print(f\"Max Value of Action -> {upper_bound}\")\n",
    "print(f\"Min Value of Action -> {lower_bound}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6d1ed9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T20:57:30.757348Z",
     "start_time": "2022-06-30T20:57:30.725348Z"
    }
   },
   "outputs": [],
   "source": [
    "class OUP:\n",
    "    \n",
    "    def __init__(self, mean, std, theta=0.15, dt=0.01, x_init=None):\n",
    "        \n",
    "        self.theta=theta\n",
    "        self.mean=mean\n",
    "        self.std=std\n",
    "        self.dt=dt\n",
    "        self.x_init=x_init\n",
    "        self.reset()\n",
    "        \n",
    "    def __call__(self):\n",
    "        \n",
    "        x = (\n",
    "            self.x_prev\n",
    "            + self.theta * ( self.mean - self.x_prev) * self.dt\n",
    "            + self.std * np.sqrt( self.dt ) * np.random.normal(size=self.mean.shape)\n",
    "        )\n",
    "        \n",
    "        self.x_prev = x\n",
    "        return x\n",
    "    \n",
    "    def reset(self):\n",
    "        \n",
    "        if self.x_init is not None:\n",
    "            self.x_prev = self.x_init\n",
    "        else:\n",
    "            sel.x_pref = np.zeros_like(self.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0131ac0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T19:30:18.427035Z",
     "start_time": "2022-06-30T19:28:02.648699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 Score -276.06498012013714\n",
      "Episode 2 Score -208.9963935503194\n",
      "Episode 3 Score -195.33711639135322\n",
      "Episode 4 Score -216.79793749645148\n",
      "Episode 5 Score -203.6981960418356\n",
      "Episode 6 Score -346.5737730341457\n",
      "Episode 7 Score -290.09933471041745\n",
      "Episode 8 Score -337.5597243881244\n",
      "Episode 9 Score -295.7072001107779\n",
      "Episode 10 Score -241.57914752196808\n",
      "Episode 11 Score -156.63793075227784\n",
      "Episode 12 Score -337.16212828974625\n",
      "Episode 13 Score -171.10593614508952\n",
      "Episode 14 Score -219.16684131172454\n",
      "Episode 15 Score -259.9653105207465\n",
      "Episode 16 Score -185.6392469173187\n",
      "Episode 17 Score -213.11745151572796\n",
      "Episode 18 Score -428.649476509421\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avell\\Trabalho\\Repos\\machine-learning-lecture\\lecvenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3406: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "episodes = 20\n",
    "for episode in range(1,episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = np.random.uniform(low=-1,high=1,size=(6,))\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        print(info)\n",
    "        score += reward\n",
    "    print('Episode {} Score {}'.format(episode,score))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d72ebe",
   "metadata": {},
   "source": [
    "## Criando o Modelo de Deep Learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecvenv",
   "language": "python",
   "name": "lecvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
